## 1.2 Our Contribution: Reconciling the Irreconcilable

We develop a reconciliation calculus for contexts (frames) and show that there is an essentially unique (under our axioms) scalar capturing the informational cost of enforcing one story across incompatible contexts.

**Axiomatic characterization (inevitability)**.
We prove that, under axioms A0â€“A5, the essentially unique contradiction measure is $K(P)=-\log_2 \alpha^\star(P)$ where $\alpha^\star(P)=\max_{Q\in \mathrm{FI}}\ \min_{c}\ \mathrm{BC}\!\big(p_c, q_c\big)$. Here $\mathrm{FI}$ is the convex set of frame-independent behaviors. In quantum settings, $\mathrm{FI}$ coincides with non-contextual models, yielding a principled violation strength.

**Agreement-kernel uniqueness.**
Assuming refinement separability, product multiplicativity, and a data-processing inequality, we show the per-context agreement is uniquely the Bhattacharyya affinity.

**Well-posedness & calibrated zero.**
For finite alphabets with $\mathrm{FI}$ nonempty/compact/convex/product-closed, the program for $\alpha^\star(P)$ attains an optimum with $\alpha^\star(P)\in[0,1]$; thus $K(P)\geq 0$ and $K(P)=0$ iff $P\in\mathrm{FI}$. And this establishes an absolute zero and a stable scale.

**Resource laws.**
And we prove additivity $K(P\otimes R)=K(P)+K(R)$ and monotonicity under free operations.

**Operational triad from one overlap.**
The same $\alpha^\star$ yields, under standard conditions: discrimination error exponents for testing real vs. simulated behavior, simulation overheads to imitate multi-context data, and prediction lower bounds.

**Computability & estimation.**
We provide a practical minimax/convex program for $\alpha^\star$, plus a consistent plug-in estimator for $K$ from empirical frequencies with bootstrap CIs.

**Specialization to quantum contextuality**.
Whenever $\mathrm{FI} =$ the non-contextual set, $K$ is a contextuality monotone..