## 2.2 The Lenticular Coin: the Natural "Both" Band

The first coin taught us a rule: $\text{LEFT}$ and $\text{RIGHT}$ must disagree. This constituted genuine learning—a discovery that reduces informational uncertainty as you understand how the device operates. After the rule is known, each flip merely confirms expectation.

To show the persisting structure we care about when we say "frame", we acknowledge a mundane physical fact about lenticular media: there is a transition band where both layers are simultaneously visible. That band is not an error; it is part of the object. Place the coin as before, but mark three viewing positions: $\text{LEFT}$, $\text{MIDDLE}$, and $\text{RIGHT}$.

Each face is printed lenticularly so being positioned at $\text{LEFT}$ cleanly shows $\text{YES}$, $\text{RIGHT}$ cleanly shows $\text{NO}$, and being at $\text{MIDDLE}$ shows natural transition band where both overlays are visibly present. When the coin flips from $\text{HEADS}$ to $\text{TAILS}$, the clean views swap ($\text{YES}$↔$\text{NO}$), yet the $\text{MIDDLE}$ never changes, always showing $\text{BOTH}$.

**Formally:**

For face $S\in\{\text{HEADS},\text{TAILS}\}$ and position $P\in\{\text{LEFT},\text{MIDDLE},\text{RIGHT}\}$, the observation $O$ satisfies
$$
O(S,P)= \begin{cases} \text{BOTH}, & P=\text{MIDDLE},\\ \text{YES},  & (S,P)\in\{(\text{HEADS},\text{LEFT}),(\text{TAILS},\text{RIGHT})\},\\ \text{NO},   & (S,P)\in\{(\text{HEADS},\text{RIGHT}),(\text{TAILS},\text{LEFT})\}. \end{cases}
$$
This is just a postcard effect, elevated to a protocol.

However, two things now become unavoidable:

1. **Ambiguity is intrinsic**. a competent observer at $\text{MIDDLE}$ can truthfully report $\text{BOTH}$; that outcome is lawful, not noise.
2. **Perspective becomes a per-trial budget**. reports are reproducible only if the viewing frame travels with the message. "I saw $\text{YES}$" is underspecified; "I saw $\text{YES}$ from $\text{LEFT}$" is reconstructible.

With three seats the law is now *context-indexed*. For a fixed seat $P$:

- $P=\text{LEFT}$: $\text{YES}$ on $\text{HEADS}$, $\text{NO}$ on $\text{TAILS}$.
- $P=\text{RIGHT}$: $\text{NO}$ on $\text{HEADS}$, $\text{YES}$ on $\text{TAILS}$ (the inverse of $\text{LEFT}$).
- $P=\text{MIDDLE}$: $\text{BOTH}$ on both flips (constant).

As a consequence, you cannot tell the full story unless **you model** $P$. There is a small but steady information loss—about  $\frac{2}{3}$ of a bit per record (Appendix B.1)—if you drop the frame. It'd be no different than asking 'did they break the law?' without saying where it happened. Run the experiment for many flips and this structure shows up in plain statistics: $\text{LEFT}$ and $\text{RIGHT}$ disagree predictably; the $\text{MIDDLE}$ registers a stable experience of $\text{BOTH}$ events; and the frame labels are continually required to reconcile otherwise incompatible yet honest reports.

The disagreement is no longer just "they always oppose" (a rule you learn once). The extra content is small, but it never goes away. It is not the one-off surprise of model identification; it is a steady coordination cost—bits you must carry every time if downstream agreement is the goal. **The** **frame is part of the message**—an operational reading of Heisenberg's dictum.

This builds an intuition on perspective: the frame itself is information, and while not entirely new, we model it far less often than we should. Shannon's model doesn't forbid modeling frames; it simply doesn't quantify incompatibility across contexts. This is not contradiction yet: the reports are consistent—but we needed to show this distinction.

We show this to distinctly separate information loss from dropping frames from structural contradiction across frames, so readers won't conflate "forgot the label" with "no single story fits."